{
  "best_metric": 0.09065347909927368,
  "best_model_checkpoint": "fine-tuned-visionllama-sensorqa\\checkpoint-1408",
  "epoch": 2.2098273572377156,
  "eval_steps": 128,
  "global_step": 1664,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005312084993359893,
      "grad_norm": 2.6147100925445557,
      "learning_rate": 0.0002,
      "loss": 2.6109,
      "step": 4
    },
    {
      "epoch": 0.010624169986719787,
      "grad_norm": 4.993069648742676,
      "learning_rate": 0.0002,
      "loss": 2.141,
      "step": 8
    },
    {
      "epoch": 0.01593625498007968,
      "grad_norm": 2.4021542072296143,
      "learning_rate": 0.0002,
      "loss": 1.6627,
      "step": 12
    },
    {
      "epoch": 0.021248339973439574,
      "grad_norm": 2.7135491371154785,
      "learning_rate": 0.0002,
      "loss": 1.1564,
      "step": 16
    },
    {
      "epoch": 0.02656042496679947,
      "grad_norm": 4.738712310791016,
      "learning_rate": 0.0002,
      "loss": 0.6333,
      "step": 20
    },
    {
      "epoch": 0.03187250996015936,
      "grad_norm": 1.3862310647964478,
      "learning_rate": 0.0002,
      "loss": 0.3185,
      "step": 24
    },
    {
      "epoch": 0.03718459495351926,
      "grad_norm": 0.8510636687278748,
      "learning_rate": 0.0002,
      "loss": 0.2243,
      "step": 28
    },
    {
      "epoch": 0.04249667994687915,
      "grad_norm": 0.5630013942718506,
      "learning_rate": 0.0002,
      "loss": 0.2034,
      "step": 32
    },
    {
      "epoch": 0.04780876494023904,
      "grad_norm": 0.47526583075523376,
      "learning_rate": 0.0002,
      "loss": 0.1905,
      "step": 36
    },
    {
      "epoch": 0.05312084993359894,
      "grad_norm": 0.4352690875530243,
      "learning_rate": 0.0002,
      "loss": 0.1961,
      "step": 40
    },
    {
      "epoch": 0.05843293492695883,
      "grad_norm": 0.4696192443370819,
      "learning_rate": 0.0002,
      "loss": 0.1993,
      "step": 44
    },
    {
      "epoch": 0.06374501992031872,
      "grad_norm": 0.4265393912792206,
      "learning_rate": 0.0002,
      "loss": 0.1825,
      "step": 48
    },
    {
      "epoch": 0.06905710491367861,
      "grad_norm": 1.4237593412399292,
      "learning_rate": 0.0002,
      "loss": 0.1555,
      "step": 52
    },
    {
      "epoch": 0.07436918990703852,
      "grad_norm": 0.40619340538978577,
      "learning_rate": 0.0002,
      "loss": 0.1752,
      "step": 56
    },
    {
      "epoch": 0.0796812749003984,
      "grad_norm": 0.3106730580329895,
      "learning_rate": 0.0002,
      "loss": 0.1475,
      "step": 60
    },
    {
      "epoch": 0.0849933598937583,
      "grad_norm": 0.38620734214782715,
      "learning_rate": 0.0002,
      "loss": 0.152,
      "step": 64
    },
    {
      "epoch": 0.0903054448871182,
      "grad_norm": 0.3586210608482361,
      "learning_rate": 0.0002,
      "loss": 0.1711,
      "step": 68
    },
    {
      "epoch": 0.09561752988047809,
      "grad_norm": 0.321628600358963,
      "learning_rate": 0.0002,
      "loss": 0.138,
      "step": 72
    },
    {
      "epoch": 0.10092961487383798,
      "grad_norm": 0.6239932775497437,
      "learning_rate": 0.0002,
      "loss": 0.1558,
      "step": 76
    },
    {
      "epoch": 0.10624169986719788,
      "grad_norm": 1.1451700925827026,
      "learning_rate": 0.0002,
      "loss": 0.1439,
      "step": 80
    },
    {
      "epoch": 0.11155378486055777,
      "grad_norm": 0.28834518790245056,
      "learning_rate": 0.0002,
      "loss": 0.128,
      "step": 84
    },
    {
      "epoch": 0.11686586985391766,
      "grad_norm": 0.672377347946167,
      "learning_rate": 0.0002,
      "loss": 0.1317,
      "step": 88
    },
    {
      "epoch": 0.12217795484727756,
      "grad_norm": 0.44840604066848755,
      "learning_rate": 0.0002,
      "loss": 0.1251,
      "step": 92
    },
    {
      "epoch": 0.12749003984063745,
      "grad_norm": 0.2951642572879791,
      "learning_rate": 0.0002,
      "loss": 0.1258,
      "step": 96
    },
    {
      "epoch": 0.13280212483399734,
      "grad_norm": 0.4195031523704529,
      "learning_rate": 0.0002,
      "loss": 0.1018,
      "step": 100
    },
    {
      "epoch": 0.13811420982735723,
      "grad_norm": 0.8475733399391174,
      "learning_rate": 0.0002,
      "loss": 0.121,
      "step": 104
    },
    {
      "epoch": 0.14342629482071714,
      "grad_norm": 0.28176066279411316,
      "learning_rate": 0.0002,
      "loss": 0.1065,
      "step": 108
    },
    {
      "epoch": 0.14873837981407703,
      "grad_norm": 0.2849377691745758,
      "learning_rate": 0.0002,
      "loss": 0.118,
      "step": 112
    },
    {
      "epoch": 0.15405046480743692,
      "grad_norm": 0.2855774760246277,
      "learning_rate": 0.0002,
      "loss": 0.1026,
      "step": 116
    },
    {
      "epoch": 0.1593625498007968,
      "grad_norm": 0.27884748578071594,
      "learning_rate": 0.0002,
      "loss": 0.1068,
      "step": 120
    },
    {
      "epoch": 0.1646746347941567,
      "grad_norm": 0.37674838304519653,
      "learning_rate": 0.0002,
      "loss": 0.1343,
      "step": 124
    },
    {
      "epoch": 0.1699867197875166,
      "grad_norm": 0.3206160068511963,
      "learning_rate": 0.0002,
      "loss": 0.0969,
      "step": 128
    },
    {
      "epoch": 0.1699867197875166,
      "eval_loss": 0.1099134087562561,
      "eval_runtime": 671.1007,
      "eval_samples_per_second": 1.684,
      "eval_steps_per_second": 0.562,
      "step": 128
    },
    {
      "epoch": 0.1752988047808765,
      "grad_norm": 0.2814284563064575,
      "learning_rate": 0.0002,
      "loss": 0.103,
      "step": 132
    },
    {
      "epoch": 0.1806108897742364,
      "grad_norm": 0.27309703826904297,
      "learning_rate": 0.0002,
      "loss": 0.1102,
      "step": 136
    },
    {
      "epoch": 0.18592297476759628,
      "grad_norm": 0.31573256850242615,
      "learning_rate": 0.0002,
      "loss": 0.1066,
      "step": 140
    },
    {
      "epoch": 0.19123505976095617,
      "grad_norm": 0.2732868492603302,
      "learning_rate": 0.0002,
      "loss": 0.0977,
      "step": 144
    },
    {
      "epoch": 0.19654714475431606,
      "grad_norm": 0.4549753963947296,
      "learning_rate": 0.0002,
      "loss": 0.1016,
      "step": 148
    },
    {
      "epoch": 0.20185922974767595,
      "grad_norm": 0.28152450919151306,
      "learning_rate": 0.0002,
      "loss": 0.1088,
      "step": 152
    },
    {
      "epoch": 0.20717131474103587,
      "grad_norm": 0.24441751837730408,
      "learning_rate": 0.0002,
      "loss": 0.0985,
      "step": 156
    },
    {
      "epoch": 0.21248339973439576,
      "grad_norm": 0.45994409918785095,
      "learning_rate": 0.0002,
      "loss": 0.1106,
      "step": 160
    },
    {
      "epoch": 0.21779548472775564,
      "grad_norm": 0.2522597312927246,
      "learning_rate": 0.0002,
      "loss": 0.0958,
      "step": 164
    },
    {
      "epoch": 0.22310756972111553,
      "grad_norm": 0.312238484621048,
      "learning_rate": 0.0002,
      "loss": 0.112,
      "step": 168
    },
    {
      "epoch": 0.22841965471447542,
      "grad_norm": 0.20979268848896027,
      "learning_rate": 0.0002,
      "loss": 0.1016,
      "step": 172
    },
    {
      "epoch": 0.2337317397078353,
      "grad_norm": 0.28705570101737976,
      "learning_rate": 0.0002,
      "loss": 0.1073,
      "step": 176
    },
    {
      "epoch": 0.23904382470119523,
      "grad_norm": 0.29857662320137024,
      "learning_rate": 0.0002,
      "loss": 0.1132,
      "step": 180
    },
    {
      "epoch": 0.24435590969455512,
      "grad_norm": 0.28380516171455383,
      "learning_rate": 0.0002,
      "loss": 0.106,
      "step": 184
    },
    {
      "epoch": 0.249667994687915,
      "grad_norm": 0.27794286608695984,
      "learning_rate": 0.0002,
      "loss": 0.1123,
      "step": 188
    },
    {
      "epoch": 0.2549800796812749,
      "grad_norm": 0.23720256984233856,
      "learning_rate": 0.0002,
      "loss": 0.0898,
      "step": 192
    },
    {
      "epoch": 0.2602921646746348,
      "grad_norm": 0.25478389859199524,
      "learning_rate": 0.0002,
      "loss": 0.1053,
      "step": 196
    },
    {
      "epoch": 0.2656042496679947,
      "grad_norm": 0.2739776074886322,
      "learning_rate": 0.0002,
      "loss": 0.0976,
      "step": 200
    },
    {
      "epoch": 0.27091633466135456,
      "grad_norm": 0.2470112293958664,
      "learning_rate": 0.0002,
      "loss": 0.0929,
      "step": 204
    },
    {
      "epoch": 0.27622841965471445,
      "grad_norm": 0.20698575675487518,
      "learning_rate": 0.0002,
      "loss": 0.106,
      "step": 208
    },
    {
      "epoch": 0.2815405046480744,
      "grad_norm": 0.20838908851146698,
      "learning_rate": 0.0002,
      "loss": 0.1042,
      "step": 212
    },
    {
      "epoch": 0.2868525896414343,
      "grad_norm": 0.24644319713115692,
      "learning_rate": 0.0002,
      "loss": 0.1206,
      "step": 216
    },
    {
      "epoch": 0.2921646746347942,
      "grad_norm": 0.24524392187595367,
      "learning_rate": 0.0002,
      "loss": 0.1068,
      "step": 220
    },
    {
      "epoch": 0.29747675962815406,
      "grad_norm": 0.2692714333534241,
      "learning_rate": 0.0002,
      "loss": 0.1192,
      "step": 224
    },
    {
      "epoch": 0.30278884462151395,
      "grad_norm": 0.275385320186615,
      "learning_rate": 0.0002,
      "loss": 0.1052,
      "step": 228
    },
    {
      "epoch": 0.30810092961487384,
      "grad_norm": 0.24580150842666626,
      "learning_rate": 0.0002,
      "loss": 0.0911,
      "step": 232
    },
    {
      "epoch": 0.31341301460823373,
      "grad_norm": 0.2557089924812317,
      "learning_rate": 0.0002,
      "loss": 0.1146,
      "step": 236
    },
    {
      "epoch": 0.3187250996015936,
      "grad_norm": 0.3171806037425995,
      "learning_rate": 0.0002,
      "loss": 0.1113,
      "step": 240
    },
    {
      "epoch": 0.3240371845949535,
      "grad_norm": 0.1902085840702057,
      "learning_rate": 0.0002,
      "loss": 0.0804,
      "step": 244
    },
    {
      "epoch": 0.3293492695883134,
      "grad_norm": 0.28232502937316895,
      "learning_rate": 0.0002,
      "loss": 0.0948,
      "step": 248
    },
    {
      "epoch": 0.3346613545816733,
      "grad_norm": 0.19198116660118103,
      "learning_rate": 0.0002,
      "loss": 0.1018,
      "step": 252
    },
    {
      "epoch": 0.3399734395750332,
      "grad_norm": 0.2261495292186737,
      "learning_rate": 0.0002,
      "loss": 0.0871,
      "step": 256
    },
    {
      "epoch": 0.3399734395750332,
      "eval_loss": 0.10306062549352646,
      "eval_runtime": 671.2744,
      "eval_samples_per_second": 1.683,
      "eval_steps_per_second": 0.562,
      "step": 256
    },
    {
      "epoch": 0.3452855245683931,
      "grad_norm": 0.2689705789089203,
      "learning_rate": 0.0002,
      "loss": 0.0976,
      "step": 260
    },
    {
      "epoch": 0.350597609561753,
      "grad_norm": 0.3090830445289612,
      "learning_rate": 0.0002,
      "loss": 0.0954,
      "step": 264
    },
    {
      "epoch": 0.3559096945551129,
      "grad_norm": 0.22191943228244781,
      "learning_rate": 0.0002,
      "loss": 0.095,
      "step": 268
    },
    {
      "epoch": 0.3612217795484728,
      "grad_norm": 0.31694355607032776,
      "learning_rate": 0.0002,
      "loss": 0.0943,
      "step": 272
    },
    {
      "epoch": 0.3665338645418327,
      "grad_norm": 0.29289722442626953,
      "learning_rate": 0.0002,
      "loss": 0.1271,
      "step": 276
    },
    {
      "epoch": 0.37184594953519257,
      "grad_norm": 0.29001113772392273,
      "learning_rate": 0.0002,
      "loss": 0.0881,
      "step": 280
    },
    {
      "epoch": 0.37715803452855245,
      "grad_norm": 0.2709459364414215,
      "learning_rate": 0.0002,
      "loss": 0.1071,
      "step": 284
    },
    {
      "epoch": 0.38247011952191234,
      "grad_norm": 0.28326231241226196,
      "learning_rate": 0.0002,
      "loss": 0.1032,
      "step": 288
    },
    {
      "epoch": 0.38778220451527223,
      "grad_norm": 0.2193341702222824,
      "learning_rate": 0.0002,
      "loss": 0.0928,
      "step": 292
    },
    {
      "epoch": 0.3930942895086321,
      "grad_norm": 0.23952358961105347,
      "learning_rate": 0.0002,
      "loss": 0.0865,
      "step": 296
    },
    {
      "epoch": 0.398406374501992,
      "grad_norm": 0.21427282691001892,
      "learning_rate": 0.0002,
      "loss": 0.1049,
      "step": 300
    },
    {
      "epoch": 0.4037184594953519,
      "grad_norm": 0.4550633132457733,
      "learning_rate": 0.0002,
      "loss": 0.1184,
      "step": 304
    },
    {
      "epoch": 0.40903054448871184,
      "grad_norm": 0.24853289127349854,
      "learning_rate": 0.0002,
      "loss": 0.0896,
      "step": 308
    },
    {
      "epoch": 0.41434262948207173,
      "grad_norm": 0.20325486361980438,
      "learning_rate": 0.0002,
      "loss": 0.0979,
      "step": 312
    },
    {
      "epoch": 0.4196547144754316,
      "grad_norm": 0.2672612965106964,
      "learning_rate": 0.0002,
      "loss": 0.0971,
      "step": 316
    },
    {
      "epoch": 0.4249667994687915,
      "grad_norm": 0.265038400888443,
      "learning_rate": 0.0002,
      "loss": 0.1166,
      "step": 320
    },
    {
      "epoch": 0.4302788844621514,
      "grad_norm": 0.2622353434562683,
      "learning_rate": 0.0002,
      "loss": 0.1113,
      "step": 324
    },
    {
      "epoch": 0.4355909694555113,
      "grad_norm": 0.22835515439510345,
      "learning_rate": 0.0002,
      "loss": 0.1014,
      "step": 328
    },
    {
      "epoch": 0.4409030544488712,
      "grad_norm": 0.2954506576061249,
      "learning_rate": 0.0002,
      "loss": 0.0963,
      "step": 332
    },
    {
      "epoch": 0.44621513944223107,
      "grad_norm": 0.21101386845111847,
      "learning_rate": 0.0002,
      "loss": 0.0957,
      "step": 336
    },
    {
      "epoch": 0.45152722443559096,
      "grad_norm": 0.34228256344795227,
      "learning_rate": 0.0002,
      "loss": 0.095,
      "step": 340
    },
    {
      "epoch": 0.45683930942895085,
      "grad_norm": 0.3328772783279419,
      "learning_rate": 0.0002,
      "loss": 0.0961,
      "step": 344
    },
    {
      "epoch": 0.46215139442231074,
      "grad_norm": 0.1924525648355484,
      "learning_rate": 0.0002,
      "loss": 0.0876,
      "step": 348
    },
    {
      "epoch": 0.4674634794156706,
      "grad_norm": 0.24412928521633148,
      "learning_rate": 0.0002,
      "loss": 0.0907,
      "step": 352
    },
    {
      "epoch": 0.47277556440903057,
      "grad_norm": 0.23628447949886322,
      "learning_rate": 0.0002,
      "loss": 0.0869,
      "step": 356
    },
    {
      "epoch": 0.47808764940239046,
      "grad_norm": 0.2702440023422241,
      "learning_rate": 0.0002,
      "loss": 0.0996,
      "step": 360
    },
    {
      "epoch": 0.48339973439575035,
      "grad_norm": 0.2503136694431305,
      "learning_rate": 0.0002,
      "loss": 0.0923,
      "step": 364
    },
    {
      "epoch": 0.48871181938911024,
      "grad_norm": 0.22291898727416992,
      "learning_rate": 0.0002,
      "loss": 0.0991,
      "step": 368
    },
    {
      "epoch": 0.4940239043824701,
      "grad_norm": 0.29867640137672424,
      "learning_rate": 0.0002,
      "loss": 0.1045,
      "step": 372
    },
    {
      "epoch": 0.49933598937583,
      "grad_norm": 0.24622300267219543,
      "learning_rate": 0.0002,
      "loss": 0.0893,
      "step": 376
    },
    {
      "epoch": 0.5046480743691899,
      "grad_norm": 0.24367791414260864,
      "learning_rate": 0.0002,
      "loss": 0.0842,
      "step": 380
    },
    {
      "epoch": 0.5099601593625498,
      "grad_norm": 0.32684803009033203,
      "learning_rate": 0.0002,
      "loss": 0.1031,
      "step": 384
    },
    {
      "epoch": 0.5099601593625498,
      "eval_loss": 0.09912410378456116,
      "eval_runtime": 670.8138,
      "eval_samples_per_second": 1.685,
      "eval_steps_per_second": 0.562,
      "step": 384
    },
    {
      "epoch": 0.5152722443559097,
      "grad_norm": 0.2587093710899353,
      "learning_rate": 0.0002,
      "loss": 0.0893,
      "step": 388
    },
    {
      "epoch": 0.5205843293492696,
      "grad_norm": 0.3273336589336395,
      "learning_rate": 0.0002,
      "loss": 0.1081,
      "step": 392
    },
    {
      "epoch": 0.5258964143426295,
      "grad_norm": 0.2390383630990982,
      "learning_rate": 0.0002,
      "loss": 0.1148,
      "step": 396
    },
    {
      "epoch": 0.5312084993359893,
      "grad_norm": 0.2512749135494232,
      "learning_rate": 0.0002,
      "loss": 0.1065,
      "step": 400
    },
    {
      "epoch": 0.5365205843293492,
      "grad_norm": 0.3632853925228119,
      "learning_rate": 0.0002,
      "loss": 0.0959,
      "step": 404
    },
    {
      "epoch": 0.5418326693227091,
      "grad_norm": 0.271310955286026,
      "learning_rate": 0.0002,
      "loss": 0.1008,
      "step": 408
    },
    {
      "epoch": 0.547144754316069,
      "grad_norm": 0.26717138290405273,
      "learning_rate": 0.0002,
      "loss": 0.096,
      "step": 412
    },
    {
      "epoch": 0.5524568393094289,
      "grad_norm": 0.22830075025558472,
      "learning_rate": 0.0002,
      "loss": 0.0835,
      "step": 416
    },
    {
      "epoch": 0.5577689243027888,
      "grad_norm": 0.27370429039001465,
      "learning_rate": 0.0002,
      "loss": 0.1028,
      "step": 420
    },
    {
      "epoch": 0.5630810092961488,
      "grad_norm": 0.31959909200668335,
      "learning_rate": 0.0002,
      "loss": 0.1066,
      "step": 424
    },
    {
      "epoch": 0.5683930942895087,
      "grad_norm": 0.20682016015052795,
      "learning_rate": 0.0002,
      "loss": 0.0855,
      "step": 428
    },
    {
      "epoch": 0.5737051792828686,
      "grad_norm": 0.18289342522621155,
      "learning_rate": 0.0002,
      "loss": 0.0786,
      "step": 432
    },
    {
      "epoch": 0.5790172642762285,
      "grad_norm": 0.2275264859199524,
      "learning_rate": 0.0002,
      "loss": 0.0989,
      "step": 436
    },
    {
      "epoch": 0.5843293492695883,
      "grad_norm": 0.20609812438488007,
      "learning_rate": 0.0002,
      "loss": 0.0934,
      "step": 440
    },
    {
      "epoch": 0.5896414342629482,
      "grad_norm": 0.5383004546165466,
      "learning_rate": 0.0002,
      "loss": 0.0867,
      "step": 444
    },
    {
      "epoch": 0.5949535192563081,
      "grad_norm": 0.28932467103004456,
      "learning_rate": 0.0002,
      "loss": 0.1107,
      "step": 448
    },
    {
      "epoch": 0.600265604249668,
      "grad_norm": 0.20046289265155792,
      "learning_rate": 0.0002,
      "loss": 0.0872,
      "step": 452
    },
    {
      "epoch": 0.6055776892430279,
      "grad_norm": 0.27260494232177734,
      "learning_rate": 0.0002,
      "loss": 0.0989,
      "step": 456
    },
    {
      "epoch": 0.6108897742363878,
      "grad_norm": 0.6167885065078735,
      "learning_rate": 0.0002,
      "loss": 0.0976,
      "step": 460
    },
    {
      "epoch": 0.6162018592297477,
      "grad_norm": 0.25898033380508423,
      "learning_rate": 0.0002,
      "loss": 0.094,
      "step": 464
    },
    {
      "epoch": 0.6215139442231076,
      "grad_norm": 0.220326766371727,
      "learning_rate": 0.0002,
      "loss": 0.1245,
      "step": 468
    },
    {
      "epoch": 0.6268260292164675,
      "grad_norm": 0.4103894531726837,
      "learning_rate": 0.0002,
      "loss": 0.1081,
      "step": 472
    },
    {
      "epoch": 0.6321381142098274,
      "grad_norm": 0.20621037483215332,
      "learning_rate": 0.0002,
      "loss": 0.0951,
      "step": 476
    },
    {
      "epoch": 0.6374501992031872,
      "grad_norm": 0.2067609280347824,
      "learning_rate": 0.0002,
      "loss": 0.1066,
      "step": 480
    },
    {
      "epoch": 0.6427622841965471,
      "grad_norm": 0.6842138171195984,
      "learning_rate": 0.0002,
      "loss": 0.0947,
      "step": 484
    },
    {
      "epoch": 0.648074369189907,
      "grad_norm": 0.23177817463874817,
      "learning_rate": 0.0002,
      "loss": 0.088,
      "step": 488
    },
    {
      "epoch": 0.6533864541832669,
      "grad_norm": 0.26843520998954773,
      "learning_rate": 0.0002,
      "loss": 0.085,
      "step": 492
    },
    {
      "epoch": 0.6586985391766268,
      "grad_norm": 0.26329296827316284,
      "learning_rate": 0.0002,
      "loss": 0.0977,
      "step": 496
    },
    {
      "epoch": 0.6640106241699867,
      "grad_norm": 0.2566085755825043,
      "learning_rate": 0.0002,
      "loss": 0.1117,
      "step": 500
    },
    {
      "epoch": 0.6693227091633466,
      "grad_norm": 0.21498195827007294,
      "learning_rate": 0.0002,
      "loss": 0.0975,
      "step": 504
    },
    {
      "epoch": 0.6746347941567065,
      "grad_norm": 0.2527233958244324,
      "learning_rate": 0.0002,
      "loss": 0.0893,
      "step": 508
    },
    {
      "epoch": 0.6799468791500664,
      "grad_norm": 0.2805294394493103,
      "learning_rate": 0.0002,
      "loss": 0.0912,
      "step": 512
    },
    {
      "epoch": 0.6799468791500664,
      "eval_loss": 0.09663950651884079,
      "eval_runtime": 671.0311,
      "eval_samples_per_second": 1.684,
      "eval_steps_per_second": 0.562,
      "step": 512
    },
    {
      "epoch": 0.6852589641434262,
      "grad_norm": 0.2969931364059448,
      "learning_rate": 0.0002,
      "loss": 0.1027,
      "step": 516
    },
    {
      "epoch": 0.6905710491367862,
      "grad_norm": 0.3242148160934448,
      "learning_rate": 0.0002,
      "loss": 0.1011,
      "step": 520
    },
    {
      "epoch": 0.6958831341301461,
      "grad_norm": 0.23316068947315216,
      "learning_rate": 0.0002,
      "loss": 0.0841,
      "step": 524
    },
    {
      "epoch": 0.701195219123506,
      "grad_norm": 0.2386440634727478,
      "learning_rate": 0.0002,
      "loss": 0.0875,
      "step": 528
    },
    {
      "epoch": 0.7065073041168659,
      "grad_norm": 0.2108108401298523,
      "learning_rate": 0.0002,
      "loss": 0.0978,
      "step": 532
    },
    {
      "epoch": 0.7118193891102258,
      "grad_norm": 0.3344561755657196,
      "learning_rate": 0.0002,
      "loss": 0.0984,
      "step": 536
    },
    {
      "epoch": 0.7171314741035857,
      "grad_norm": 0.1760772168636322,
      "learning_rate": 0.0002,
      "loss": 0.0889,
      "step": 540
    },
    {
      "epoch": 0.7224435590969456,
      "grad_norm": 0.2160266488790512,
      "learning_rate": 0.0002,
      "loss": 0.1101,
      "step": 544
    },
    {
      "epoch": 0.7277556440903055,
      "grad_norm": 0.22227780520915985,
      "learning_rate": 0.0002,
      "loss": 0.0871,
      "step": 548
    },
    {
      "epoch": 0.7330677290836654,
      "grad_norm": 0.2722613513469696,
      "learning_rate": 0.0002,
      "loss": 0.1056,
      "step": 552
    },
    {
      "epoch": 0.7383798140770252,
      "grad_norm": 0.21122583746910095,
      "learning_rate": 0.0002,
      "loss": 0.0873,
      "step": 556
    },
    {
      "epoch": 0.7436918990703851,
      "grad_norm": 0.21841149032115936,
      "learning_rate": 0.0002,
      "loss": 0.1066,
      "step": 560
    },
    {
      "epoch": 0.749003984063745,
      "grad_norm": 1.425917625427246,
      "learning_rate": 0.0002,
      "loss": 0.1062,
      "step": 564
    },
    {
      "epoch": 0.7543160690571049,
      "grad_norm": 0.20077304542064667,
      "learning_rate": 0.0002,
      "loss": 0.1032,
      "step": 568
    },
    {
      "epoch": 0.7596281540504648,
      "grad_norm": 0.2172885686159134,
      "learning_rate": 0.0002,
      "loss": 0.102,
      "step": 572
    },
    {
      "epoch": 0.7649402390438247,
      "grad_norm": 0.28224271535873413,
      "learning_rate": 0.0002,
      "loss": 0.0906,
      "step": 576
    },
    {
      "epoch": 0.7702523240371846,
      "grad_norm": 0.35513174533843994,
      "learning_rate": 0.0002,
      "loss": 0.1099,
      "step": 580
    },
    {
      "epoch": 0.7755644090305445,
      "grad_norm": 0.21577201783657074,
      "learning_rate": 0.0002,
      "loss": 0.0986,
      "step": 584
    },
    {
      "epoch": 0.7808764940239044,
      "grad_norm": 0.2508811950683594,
      "learning_rate": 0.0002,
      "loss": 0.1006,
      "step": 588
    },
    {
      "epoch": 0.7861885790172642,
      "grad_norm": 0.17435702681541443,
      "learning_rate": 0.0002,
      "loss": 0.0918,
      "step": 592
    },
    {
      "epoch": 0.7915006640106241,
      "grad_norm": 0.23226791620254517,
      "learning_rate": 0.0002,
      "loss": 0.0929,
      "step": 596
    },
    {
      "epoch": 0.796812749003984,
      "grad_norm": 0.1998063027858734,
      "learning_rate": 0.0002,
      "loss": 0.082,
      "step": 600
    },
    {
      "epoch": 0.8021248339973439,
      "grad_norm": 0.2078932374715805,
      "learning_rate": 0.0002,
      "loss": 0.0876,
      "step": 604
    },
    {
      "epoch": 0.8074369189907038,
      "grad_norm": 0.21836915612220764,
      "learning_rate": 0.0002,
      "loss": 0.1113,
      "step": 608
    },
    {
      "epoch": 0.8127490039840638,
      "grad_norm": 0.2026720494031906,
      "learning_rate": 0.0002,
      "loss": 0.1199,
      "step": 612
    },
    {
      "epoch": 0.8180610889774237,
      "grad_norm": 0.1977020502090454,
      "learning_rate": 0.0002,
      "loss": 0.1041,
      "step": 616
    },
    {
      "epoch": 0.8233731739707836,
      "grad_norm": 0.22719316184520721,
      "learning_rate": 0.0002,
      "loss": 0.093,
      "step": 620
    },
    {
      "epoch": 0.8286852589641435,
      "grad_norm": 0.2677581012248993,
      "learning_rate": 0.0002,
      "loss": 0.1142,
      "step": 624
    },
    {
      "epoch": 0.8339973439575034,
      "grad_norm": 0.1979856789112091,
      "learning_rate": 0.0002,
      "loss": 0.0886,
      "step": 628
    },
    {
      "epoch": 0.8393094289508632,
      "grad_norm": 0.22553588449954987,
      "learning_rate": 0.0002,
      "loss": 0.0866,
      "step": 632
    },
    {
      "epoch": 0.8446215139442231,
      "grad_norm": 0.2570090889930725,
      "learning_rate": 0.0002,
      "loss": 0.1161,
      "step": 636
    },
    {
      "epoch": 0.849933598937583,
      "grad_norm": 0.1843799650669098,
      "learning_rate": 0.0002,
      "loss": 0.0878,
      "step": 640
    },
    {
      "epoch": 0.849933598937583,
      "eval_loss": 0.09530547261238098,
      "eval_runtime": 671.2242,
      "eval_samples_per_second": 1.683,
      "eval_steps_per_second": 0.562,
      "step": 640
    },
    {
      "epoch": 0.8552456839309429,
      "grad_norm": 0.26408475637435913,
      "learning_rate": 0.0002,
      "loss": 0.1015,
      "step": 644
    },
    {
      "epoch": 0.8605577689243028,
      "grad_norm": 0.27549296617507935,
      "learning_rate": 0.0002,
      "loss": 0.0983,
      "step": 648
    },
    {
      "epoch": 0.8658698539176627,
      "grad_norm": 0.2979930341243744,
      "learning_rate": 0.0002,
      "loss": 0.0984,
      "step": 652
    },
    {
      "epoch": 0.8711819389110226,
      "grad_norm": 0.2704545259475708,
      "learning_rate": 0.0002,
      "loss": 0.1139,
      "step": 656
    },
    {
      "epoch": 0.8764940239043825,
      "grad_norm": 0.1961330771446228,
      "learning_rate": 0.0002,
      "loss": 0.1066,
      "step": 660
    },
    {
      "epoch": 0.8818061088977424,
      "grad_norm": 0.3168545663356781,
      "learning_rate": 0.0002,
      "loss": 0.0991,
      "step": 664
    },
    {
      "epoch": 0.8871181938911022,
      "grad_norm": 0.20035535097122192,
      "learning_rate": 0.0002,
      "loss": 0.092,
      "step": 668
    },
    {
      "epoch": 0.8924302788844621,
      "grad_norm": 0.2360532432794571,
      "learning_rate": 0.0002,
      "loss": 0.0938,
      "step": 672
    },
    {
      "epoch": 0.897742363877822,
      "grad_norm": 0.1623600870370865,
      "learning_rate": 0.0002,
      "loss": 0.1026,
      "step": 676
    },
    {
      "epoch": 0.9030544488711819,
      "grad_norm": 0.1813964992761612,
      "learning_rate": 0.0002,
      "loss": 0.0895,
      "step": 680
    },
    {
      "epoch": 0.9083665338645418,
      "grad_norm": 0.16500014066696167,
      "learning_rate": 0.0002,
      "loss": 0.0968,
      "step": 684
    },
    {
      "epoch": 0.9136786188579017,
      "grad_norm": 0.26491984724998474,
      "learning_rate": 0.0002,
      "loss": 0.0934,
      "step": 688
    },
    {
      "epoch": 0.9189907038512616,
      "grad_norm": 0.24693654477596283,
      "learning_rate": 0.0002,
      "loss": 0.0941,
      "step": 692
    },
    {
      "epoch": 0.9243027888446215,
      "grad_norm": 0.18912354111671448,
      "learning_rate": 0.0002,
      "loss": 0.1052,
      "step": 696
    },
    {
      "epoch": 0.9296148738379814,
      "grad_norm": 0.2348700761795044,
      "learning_rate": 0.0002,
      "loss": 0.1067,
      "step": 700
    },
    {
      "epoch": 0.9349269588313412,
      "grad_norm": 0.19853028655052185,
      "learning_rate": 0.0002,
      "loss": 0.093,
      "step": 704
    },
    {
      "epoch": 0.9402390438247012,
      "grad_norm": 0.3116227686405182,
      "learning_rate": 0.0002,
      "loss": 0.1048,
      "step": 708
    },
    {
      "epoch": 0.9455511288180611,
      "grad_norm": 0.16877853870391846,
      "learning_rate": 0.0002,
      "loss": 0.0692,
      "step": 712
    },
    {
      "epoch": 0.950863213811421,
      "grad_norm": 0.25822189450263977,
      "learning_rate": 0.0002,
      "loss": 0.0953,
      "step": 716
    },
    {
      "epoch": 0.9561752988047809,
      "grad_norm": 0.2918723225593567,
      "learning_rate": 0.0002,
      "loss": 0.1015,
      "step": 720
    },
    {
      "epoch": 0.9614873837981408,
      "grad_norm": 0.19458040595054626,
      "learning_rate": 0.0002,
      "loss": 0.0981,
      "step": 724
    },
    {
      "epoch": 0.9667994687915007,
      "grad_norm": 0.18634440004825592,
      "learning_rate": 0.0002,
      "loss": 0.0714,
      "step": 728
    },
    {
      "epoch": 0.9721115537848606,
      "grad_norm": 0.17981112003326416,
      "learning_rate": 0.0002,
      "loss": 0.0691,
      "step": 732
    },
    {
      "epoch": 0.9774236387782205,
      "grad_norm": 0.24147304892539978,
      "learning_rate": 0.0002,
      "loss": 0.0885,
      "step": 736
    },
    {
      "epoch": 0.9827357237715804,
      "grad_norm": 0.22423964738845825,
      "learning_rate": 0.0002,
      "loss": 0.0925,
      "step": 740
    },
    {
      "epoch": 0.9880478087649402,
      "grad_norm": 0.22017614543437958,
      "learning_rate": 0.0002,
      "loss": 0.095,
      "step": 744
    },
    {
      "epoch": 0.9933598937583001,
      "grad_norm": 0.26587212085723877,
      "learning_rate": 0.0002,
      "loss": 0.0957,
      "step": 748
    },
    {
      "epoch": 0.99867197875166,
      "grad_norm": 0.19334295392036438,
      "learning_rate": 0.0002,
      "loss": 0.0897,
      "step": 752
    },
    {
      "epoch": 1.00398406374502,
      "grad_norm": 0.18846017122268677,
      "learning_rate": 0.0002,
      "loss": 0.092,
      "step": 756
    },
    {
      "epoch": 1.0092961487383798,
      "grad_norm": 0.21269431710243225,
      "learning_rate": 0.0002,
      "loss": 0.077,
      "step": 760
    },
    {
      "epoch": 1.0146082337317397,
      "grad_norm": 0.1969769150018692,
      "learning_rate": 0.0002,
      "loss": 0.082,
      "step": 764
    },
    {
      "epoch": 1.0199203187250996,
      "grad_norm": 0.269403338432312,
      "learning_rate": 0.0002,
      "loss": 0.08,
      "step": 768
    },
    {
      "epoch": 1.0199203187250996,
      "eval_loss": 0.09555474668741226,
      "eval_runtime": 670.4695,
      "eval_samples_per_second": 1.685,
      "eval_steps_per_second": 0.562,
      "step": 768
    },
    {
      "epoch": 1.0252324037184595,
      "grad_norm": 0.3001089096069336,
      "learning_rate": 0.0002,
      "loss": 0.0996,
      "step": 772
    },
    {
      "epoch": 1.0305444887118194,
      "grad_norm": 0.23866428434848785,
      "learning_rate": 0.0002,
      "loss": 0.1079,
      "step": 776
    },
    {
      "epoch": 1.0358565737051793,
      "grad_norm": 0.20620059967041016,
      "learning_rate": 0.0002,
      "loss": 0.0775,
      "step": 780
    },
    {
      "epoch": 1.0411686586985391,
      "grad_norm": 0.27318131923675537,
      "learning_rate": 0.0002,
      "loss": 0.1018,
      "step": 784
    },
    {
      "epoch": 1.046480743691899,
      "grad_norm": 0.20228509604930878,
      "learning_rate": 0.0002,
      "loss": 0.0672,
      "step": 788
    },
    {
      "epoch": 1.051792828685259,
      "grad_norm": 0.24066363275051117,
      "learning_rate": 0.0002,
      "loss": 0.0886,
      "step": 792
    },
    {
      "epoch": 1.0571049136786188,
      "grad_norm": 0.21886923909187317,
      "learning_rate": 0.0002,
      "loss": 0.0799,
      "step": 796
    },
    {
      "epoch": 1.0624169986719787,
      "grad_norm": 0.21804335713386536,
      "learning_rate": 0.0002,
      "loss": 0.0966,
      "step": 800
    },
    {
      "epoch": 1.0677290836653386,
      "grad_norm": 0.2654452323913574,
      "learning_rate": 0.0002,
      "loss": 0.0831,
      "step": 804
    },
    {
      "epoch": 1.0730411686586985,
      "grad_norm": 0.182956263422966,
      "learning_rate": 0.0002,
      "loss": 0.0954,
      "step": 808
    },
    {
      "epoch": 1.0783532536520584,
      "grad_norm": 0.30996188521385193,
      "learning_rate": 0.0002,
      "loss": 0.0813,
      "step": 812
    },
    {
      "epoch": 1.0836653386454183,
      "grad_norm": 0.2476232647895813,
      "learning_rate": 0.0002,
      "loss": 0.0912,
      "step": 816
    },
    {
      "epoch": 1.0889774236387781,
      "grad_norm": 0.2366061955690384,
      "learning_rate": 0.0002,
      "loss": 0.0829,
      "step": 820
    },
    {
      "epoch": 1.094289508632138,
      "grad_norm": 0.26784059405326843,
      "learning_rate": 0.0002,
      "loss": 0.0986,
      "step": 824
    },
    {
      "epoch": 1.099601593625498,
      "grad_norm": 0.19002559781074524,
      "learning_rate": 0.0002,
      "loss": 0.0778,
      "step": 828
    },
    {
      "epoch": 1.1049136786188578,
      "grad_norm": 0.22403012216091156,
      "learning_rate": 0.0002,
      "loss": 0.0863,
      "step": 832
    },
    {
      "epoch": 1.1102257636122177,
      "grad_norm": 0.21619613468647003,
      "learning_rate": 0.0002,
      "loss": 0.0735,
      "step": 836
    },
    {
      "epoch": 1.1155378486055776,
      "grad_norm": 0.19757764041423798,
      "learning_rate": 0.0002,
      "loss": 0.0914,
      "step": 840
    },
    {
      "epoch": 1.1208499335989375,
      "grad_norm": 0.22827698290348053,
      "learning_rate": 0.0002,
      "loss": 0.0866,
      "step": 844
    },
    {
      "epoch": 1.1261620185922974,
      "grad_norm": 0.2239614874124527,
      "learning_rate": 0.0002,
      "loss": 0.0966,
      "step": 848
    },
    {
      "epoch": 1.1314741035856573,
      "grad_norm": 0.19334712624549866,
      "learning_rate": 0.0002,
      "loss": 0.0939,
      "step": 852
    },
    {
      "epoch": 1.1367861885790171,
      "grad_norm": 0.19270887970924377,
      "learning_rate": 0.0002,
      "loss": 0.0895,
      "step": 856
    },
    {
      "epoch": 1.1420982735723773,
      "grad_norm": 0.17917142808437347,
      "learning_rate": 0.0002,
      "loss": 0.0719,
      "step": 860
    },
    {
      "epoch": 1.1474103585657371,
      "grad_norm": 0.24522097408771515,
      "learning_rate": 0.0002,
      "loss": 0.0982,
      "step": 864
    },
    {
      "epoch": 1.152722443559097,
      "grad_norm": 0.20570094883441925,
      "learning_rate": 0.0002,
      "loss": 0.0767,
      "step": 868
    },
    {
      "epoch": 1.158034528552457,
      "grad_norm": 0.31406429409980774,
      "learning_rate": 0.0002,
      "loss": 0.091,
      "step": 872
    },
    {
      "epoch": 1.1633466135458168,
      "grad_norm": 0.2331008017063141,
      "learning_rate": 0.0002,
      "loss": 0.0966,
      "step": 876
    },
    {
      "epoch": 1.1686586985391767,
      "grad_norm": 0.19937573373317719,
      "learning_rate": 0.0002,
      "loss": 0.0872,
      "step": 880
    },
    {
      "epoch": 1.1739707835325366,
      "grad_norm": 0.2572900652885437,
      "learning_rate": 0.0002,
      "loss": 0.0913,
      "step": 884
    },
    {
      "epoch": 1.1792828685258965,
      "grad_norm": 0.189387708902359,
      "learning_rate": 0.0002,
      "loss": 0.0866,
      "step": 888
    },
    {
      "epoch": 1.1845949535192564,
      "grad_norm": 0.24026650190353394,
      "learning_rate": 0.0002,
      "loss": 0.0973,
      "step": 892
    },
    {
      "epoch": 1.1899070385126163,
      "grad_norm": 0.2015051692724228,
      "learning_rate": 0.0002,
      "loss": 0.0871,
      "step": 896
    },
    {
      "epoch": 1.1899070385126163,
      "eval_loss": 0.09350650757551193,
      "eval_runtime": 669.9837,
      "eval_samples_per_second": 1.687,
      "eval_steps_per_second": 0.563,
      "step": 896
    },
    {
      "epoch": 1.1952191235059761,
      "grad_norm": 0.18547877669334412,
      "learning_rate": 0.0002,
      "loss": 0.0759,
      "step": 900
    },
    {
      "epoch": 1.200531208499336,
      "grad_norm": 0.18671728670597076,
      "learning_rate": 0.0002,
      "loss": 0.0738,
      "step": 904
    },
    {
      "epoch": 1.205843293492696,
      "grad_norm": 0.25323981046676636,
      "learning_rate": 0.0002,
      "loss": 0.0907,
      "step": 908
    },
    {
      "epoch": 1.2111553784860558,
      "grad_norm": 0.24082958698272705,
      "learning_rate": 0.0002,
      "loss": 0.1029,
      "step": 912
    },
    {
      "epoch": 1.2164674634794157,
      "grad_norm": 0.15429376065731049,
      "learning_rate": 0.0002,
      "loss": 0.0779,
      "step": 916
    },
    {
      "epoch": 1.2217795484727756,
      "grad_norm": 0.27712684869766235,
      "learning_rate": 0.0002,
      "loss": 0.0985,
      "step": 920
    },
    {
      "epoch": 1.2270916334661355,
      "grad_norm": 0.2214844524860382,
      "learning_rate": 0.0002,
      "loss": 0.0955,
      "step": 924
    },
    {
      "epoch": 1.2324037184594954,
      "grad_norm": 0.20510248839855194,
      "learning_rate": 0.0002,
      "loss": 0.0802,
      "step": 928
    },
    {
      "epoch": 1.2377158034528553,
      "grad_norm": 0.21585191786289215,
      "learning_rate": 0.0002,
      "loss": 0.0981,
      "step": 932
    },
    {
      "epoch": 1.2430278884462151,
      "grad_norm": 0.3155651390552521,
      "learning_rate": 0.0002,
      "loss": 0.0908,
      "step": 936
    },
    {
      "epoch": 1.248339973439575,
      "grad_norm": 0.22453992068767548,
      "learning_rate": 0.0002,
      "loss": 0.0856,
      "step": 940
    },
    {
      "epoch": 1.253652058432935,
      "grad_norm": 0.23017774522304535,
      "learning_rate": 0.0002,
      "loss": 0.1054,
      "step": 944
    },
    {
      "epoch": 1.2589641434262948,
      "grad_norm": 0.2133820652961731,
      "learning_rate": 0.0002,
      "loss": 0.0752,
      "step": 948
    },
    {
      "epoch": 1.2642762284196547,
      "grad_norm": 0.19057714939117432,
      "learning_rate": 0.0002,
      "loss": 0.0869,
      "step": 952
    },
    {
      "epoch": 1.2695883134130146,
      "grad_norm": 0.2534617483615875,
      "learning_rate": 0.0002,
      "loss": 0.0842,
      "step": 956
    },
    {
      "epoch": 1.2749003984063745,
      "grad_norm": 0.3068065345287323,
      "learning_rate": 0.0002,
      "loss": 0.082,
      "step": 960
    },
    {
      "epoch": 1.2802124833997344,
      "grad_norm": 0.30209869146347046,
      "learning_rate": 0.0002,
      "loss": 0.093,
      "step": 964
    },
    {
      "epoch": 1.2855245683930943,
      "grad_norm": 0.29860004782676697,
      "learning_rate": 0.0002,
      "loss": 0.0978,
      "step": 968
    },
    {
      "epoch": 1.2908366533864541,
      "grad_norm": 0.1690535992383957,
      "learning_rate": 0.0002,
      "loss": 0.0666,
      "step": 972
    },
    {
      "epoch": 1.296148738379814,
      "grad_norm": 0.22619444131851196,
      "learning_rate": 0.0002,
      "loss": 0.0798,
      "step": 976
    },
    {
      "epoch": 1.301460823373174,
      "grad_norm": 0.19398005306720734,
      "learning_rate": 0.0002,
      "loss": 0.0891,
      "step": 980
    },
    {
      "epoch": 1.3067729083665338,
      "grad_norm": 0.19710630178451538,
      "learning_rate": 0.0002,
      "loss": 0.0987,
      "step": 984
    },
    {
      "epoch": 1.3120849933598937,
      "grad_norm": 0.23515968024730682,
      "learning_rate": 0.0002,
      "loss": 0.0913,
      "step": 988
    },
    {
      "epoch": 1.3173970783532536,
      "grad_norm": 0.31814879179000854,
      "learning_rate": 0.0002,
      "loss": 0.1017,
      "step": 992
    },
    {
      "epoch": 1.3227091633466135,
      "grad_norm": 0.21150259673595428,
      "learning_rate": 0.0002,
      "loss": 0.0943,
      "step": 996
    },
    {
      "epoch": 1.3280212483399734,
      "grad_norm": 0.20382802188396454,
      "learning_rate": 0.0002,
      "loss": 0.0827,
      "step": 1000
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.20863303542137146,
      "learning_rate": 0.0002,
      "loss": 0.0951,
      "step": 1004
    },
    {
      "epoch": 1.3386454183266931,
      "grad_norm": 0.23995327949523926,
      "learning_rate": 0.0002,
      "loss": 0.0947,
      "step": 1008
    },
    {
      "epoch": 1.3439575033200533,
      "grad_norm": 0.18589800596237183,
      "learning_rate": 0.0002,
      "loss": 0.0874,
      "step": 1012
    },
    {
      "epoch": 1.3492695883134131,
      "grad_norm": 0.17699816823005676,
      "learning_rate": 0.0002,
      "loss": 0.0866,
      "step": 1016
    },
    {
      "epoch": 1.354581673306773,
      "grad_norm": 0.2013215869665146,
      "learning_rate": 0.0002,
      "loss": 0.0891,
      "step": 1020
    },
    {
      "epoch": 1.359893758300133,
      "grad_norm": 0.21351109445095062,
      "learning_rate": 0.0002,
      "loss": 0.104,
      "step": 1024
    },
    {
      "epoch": 1.359893758300133,
      "eval_loss": 0.09259498864412308,
      "eval_runtime": 670.518,
      "eval_samples_per_second": 1.685,
      "eval_steps_per_second": 0.562,
      "step": 1024
    },
    {
      "epoch": 1.3652058432934928,
      "grad_norm": 0.25668537616729736,
      "learning_rate": 0.0002,
      "loss": 0.0915,
      "step": 1028
    },
    {
      "epoch": 1.3705179282868527,
      "grad_norm": 0.19078285992145538,
      "learning_rate": 0.0002,
      "loss": 0.0857,
      "step": 1032
    },
    {
      "epoch": 1.3758300132802126,
      "grad_norm": 0.19061224162578583,
      "learning_rate": 0.0002,
      "loss": 0.0934,
      "step": 1036
    },
    {
      "epoch": 1.3811420982735725,
      "grad_norm": 0.22827598452568054,
      "learning_rate": 0.0002,
      "loss": 0.0888,
      "step": 1040
    },
    {
      "epoch": 1.3864541832669324,
      "grad_norm": 0.17978402972221375,
      "learning_rate": 0.0002,
      "loss": 0.0727,
      "step": 1044
    },
    {
      "epoch": 1.3917662682602923,
      "grad_norm": 0.19555097818374634,
      "learning_rate": 0.0002,
      "loss": 0.0949,
      "step": 1048
    },
    {
      "epoch": 1.3970783532536521,
      "grad_norm": 0.24207331240177155,
      "learning_rate": 0.0002,
      "loss": 0.0869,
      "step": 1052
    },
    {
      "epoch": 1.402390438247012,
      "grad_norm": 0.18662306666374207,
      "learning_rate": 0.0002,
      "loss": 0.0739,
      "step": 1056
    },
    {
      "epoch": 1.407702523240372,
      "grad_norm": 0.22518353164196014,
      "learning_rate": 0.0002,
      "loss": 0.0755,
      "step": 1060
    },
    {
      "epoch": 1.4130146082337318,
      "grad_norm": 0.22264468669891357,
      "learning_rate": 0.0002,
      "loss": 0.1026,
      "step": 1064
    },
    {
      "epoch": 1.4183266932270917,
      "grad_norm": 0.2588847577571869,
      "learning_rate": 0.0002,
      "loss": 0.099,
      "step": 1068
    },
    {
      "epoch": 1.4236387782204516,
      "grad_norm": 0.22393299639225006,
      "learning_rate": 0.0002,
      "loss": 0.0985,
      "step": 1072
    },
    {
      "epoch": 1.4289508632138115,
      "grad_norm": 0.20890210568904877,
      "learning_rate": 0.0002,
      "loss": 0.0802,
      "step": 1076
    },
    {
      "epoch": 1.4342629482071714,
      "grad_norm": 0.21217350661754608,
      "learning_rate": 0.0002,
      "loss": 0.0818,
      "step": 1080
    },
    {
      "epoch": 1.4395750332005313,
      "grad_norm": 0.25755855441093445,
      "learning_rate": 0.0002,
      "loss": 0.0874,
      "step": 1084
    },
    {
      "epoch": 1.4448871181938912,
      "grad_norm": 0.22608526051044464,
      "learning_rate": 0.0002,
      "loss": 0.0779,
      "step": 1088
    },
    {
      "epoch": 1.450199203187251,
      "grad_norm": 0.2202351838350296,
      "learning_rate": 0.0002,
      "loss": 0.0962,
      "step": 1092
    },
    {
      "epoch": 1.455511288180611,
      "grad_norm": 0.19253438711166382,
      "learning_rate": 0.0002,
      "loss": 0.0898,
      "step": 1096
    },
    {
      "epoch": 1.4608233731739708,
      "grad_norm": 0.13948480784893036,
      "learning_rate": 0.0002,
      "loss": 0.091,
      "step": 1100
    },
    {
      "epoch": 1.4661354581673307,
      "grad_norm": 0.2399139702320099,
      "learning_rate": 0.0002,
      "loss": 0.108,
      "step": 1104
    },
    {
      "epoch": 1.4714475431606906,
      "grad_norm": 0.22425074875354767,
      "learning_rate": 0.0002,
      "loss": 0.0932,
      "step": 1108
    },
    {
      "epoch": 1.4767596281540505,
      "grad_norm": 0.3082321584224701,
      "learning_rate": 0.0002,
      "loss": 0.0952,
      "step": 1112
    },
    {
      "epoch": 1.4820717131474104,
      "grad_norm": 0.23862025141716003,
      "learning_rate": 0.0002,
      "loss": 0.0917,
      "step": 1116
    },
    {
      "epoch": 1.4873837981407703,
      "grad_norm": 0.19306746125221252,
      "learning_rate": 0.0002,
      "loss": 0.0823,
      "step": 1120
    },
    {
      "epoch": 1.4926958831341302,
      "grad_norm": 0.19925473630428314,
      "learning_rate": 0.0002,
      "loss": 0.0877,
      "step": 1124
    },
    {
      "epoch": 1.49800796812749,
      "grad_norm": 0.22114647924900055,
      "learning_rate": 0.0002,
      "loss": 0.0847,
      "step": 1128
    },
    {
      "epoch": 1.50332005312085,
      "grad_norm": 0.19204363226890564,
      "learning_rate": 0.0002,
      "loss": 0.0913,
      "step": 1132
    },
    {
      "epoch": 1.5086321381142098,
      "grad_norm": 0.229158416390419,
      "learning_rate": 0.0002,
      "loss": 0.0796,
      "step": 1136
    },
    {
      "epoch": 1.5139442231075697,
      "grad_norm": 0.2313140481710434,
      "learning_rate": 0.0002,
      "loss": 0.0927,
      "step": 1140
    },
    {
      "epoch": 1.5192563081009296,
      "grad_norm": 0.21801701188087463,
      "learning_rate": 0.0002,
      "loss": 0.0783,
      "step": 1144
    },
    {
      "epoch": 1.5245683930942895,
      "grad_norm": 0.2352501004934311,
      "learning_rate": 0.0002,
      "loss": 0.0867,
      "step": 1148
    },
    {
      "epoch": 1.5298804780876494,
      "grad_norm": 0.21779102087020874,
      "learning_rate": 0.0002,
      "loss": 0.0968,
      "step": 1152
    },
    {
      "epoch": 1.5298804780876494,
      "eval_loss": 0.0919743999838829,
      "eval_runtime": 670.2215,
      "eval_samples_per_second": 1.686,
      "eval_steps_per_second": 0.563,
      "step": 1152
    },
    {
      "epoch": 1.5351925630810093,
      "grad_norm": 0.1615018993616104,
      "learning_rate": 0.0002,
      "loss": 0.0939,
      "step": 1156
    },
    {
      "epoch": 1.5405046480743692,
      "grad_norm": 0.21356813609600067,
      "learning_rate": 0.0002,
      "loss": 0.0842,
      "step": 1160
    },
    {
      "epoch": 1.545816733067729,
      "grad_norm": 0.2846132814884186,
      "learning_rate": 0.0002,
      "loss": 0.0984,
      "step": 1164
    },
    {
      "epoch": 1.551128818061089,
      "grad_norm": 0.21616898477077484,
      "learning_rate": 0.0002,
      "loss": 0.0772,
      "step": 1168
    },
    {
      "epoch": 1.5564409030544488,
      "grad_norm": 0.2967105209827423,
      "learning_rate": 0.0002,
      "loss": 0.0852,
      "step": 1172
    },
    {
      "epoch": 1.5617529880478087,
      "grad_norm": 0.2274460345506668,
      "learning_rate": 0.0002,
      "loss": 0.095,
      "step": 1176
    },
    {
      "epoch": 1.5670650730411686,
      "grad_norm": 0.2835081219673157,
      "learning_rate": 0.0002,
      "loss": 0.1007,
      "step": 1180
    },
    {
      "epoch": 1.5723771580345285,
      "grad_norm": 0.29356586933135986,
      "learning_rate": 0.0002,
      "loss": 0.1015,
      "step": 1184
    },
    {
      "epoch": 1.5776892430278884,
      "grad_norm": 0.15368454158306122,
      "learning_rate": 0.0002,
      "loss": 0.0742,
      "step": 1188
    },
    {
      "epoch": 1.5830013280212483,
      "grad_norm": 0.16859503090381622,
      "learning_rate": 0.0002,
      "loss": 0.0827,
      "step": 1192
    },
    {
      "epoch": 1.5883134130146082,
      "grad_norm": 0.2561984062194824,
      "learning_rate": 0.0002,
      "loss": 0.0921,
      "step": 1196
    },
    {
      "epoch": 1.593625498007968,
      "grad_norm": 0.24486787617206573,
      "learning_rate": 0.0002,
      "loss": 0.0944,
      "step": 1200
    },
    {
      "epoch": 1.598937583001328,
      "grad_norm": 0.2407931089401245,
      "learning_rate": 0.0002,
      "loss": 0.0816,
      "step": 1204
    },
    {
      "epoch": 1.6042496679946878,
      "grad_norm": 0.19101954996585846,
      "learning_rate": 0.0002,
      "loss": 0.1109,
      "step": 1208
    },
    {
      "epoch": 1.6095617529880477,
      "grad_norm": 0.372977077960968,
      "learning_rate": 0.0002,
      "loss": 0.0866,
      "step": 1212
    },
    {
      "epoch": 1.6148738379814076,
      "grad_norm": 0.19527849555015564,
      "learning_rate": 0.0002,
      "loss": 0.0844,
      "step": 1216
    },
    {
      "epoch": 1.6201859229747675,
      "grad_norm": 0.23415540158748627,
      "learning_rate": 0.0002,
      "loss": 0.0808,
      "step": 1220
    },
    {
      "epoch": 1.6254980079681274,
      "grad_norm": 0.2238820642232895,
      "learning_rate": 0.0002,
      "loss": 0.095,
      "step": 1224
    },
    {
      "epoch": 1.6308100929614873,
      "grad_norm": 0.27864721417427063,
      "learning_rate": 0.0002,
      "loss": 0.1071,
      "step": 1228
    },
    {
      "epoch": 1.6361221779548472,
      "grad_norm": 0.3653167188167572,
      "learning_rate": 0.0002,
      "loss": 0.1025,
      "step": 1232
    },
    {
      "epoch": 1.641434262948207,
      "grad_norm": 0.21757887303829193,
      "learning_rate": 0.0002,
      "loss": 0.0904,
      "step": 1236
    },
    {
      "epoch": 1.646746347941567,
      "grad_norm": 0.23993246257305145,
      "learning_rate": 0.0002,
      "loss": 0.0929,
      "step": 1240
    },
    {
      "epoch": 1.6520584329349268,
      "grad_norm": 0.19891664385795593,
      "learning_rate": 0.0002,
      "loss": 0.0878,
      "step": 1244
    },
    {
      "epoch": 1.6573705179282867,
      "grad_norm": 0.16166777908802032,
      "learning_rate": 0.0002,
      "loss": 0.076,
      "step": 1248
    },
    {
      "epoch": 1.6626826029216466,
      "grad_norm": 0.21174974739551544,
      "learning_rate": 0.0002,
      "loss": 0.0813,
      "step": 1252
    },
    {
      "epoch": 1.6679946879150065,
      "grad_norm": 0.1710873395204544,
      "learning_rate": 0.0002,
      "loss": 0.0994,
      "step": 1256
    },
    {
      "epoch": 1.6733067729083664,
      "grad_norm": 0.20536236464977264,
      "learning_rate": 0.0002,
      "loss": 0.0914,
      "step": 1260
    },
    {
      "epoch": 1.6786188579017263,
      "grad_norm": 0.2635232210159302,
      "learning_rate": 0.0002,
      "loss": 0.0809,
      "step": 1264
    },
    {
      "epoch": 1.6839309428950862,
      "grad_norm": 0.22183966636657715,
      "learning_rate": 0.0002,
      "loss": 0.0882,
      "step": 1268
    },
    {
      "epoch": 1.6892430278884463,
      "grad_norm": 0.16291669011116028,
      "learning_rate": 0.0002,
      "loss": 0.0678,
      "step": 1272
    },
    {
      "epoch": 1.6945551128818062,
      "grad_norm": 0.2794956862926483,
      "learning_rate": 0.0002,
      "loss": 0.0761,
      "step": 1276
    },
    {
      "epoch": 1.699867197875166,
      "grad_norm": 0.16562724113464355,
      "learning_rate": 0.0002,
      "loss": 0.0762,
      "step": 1280
    },
    {
      "epoch": 1.699867197875166,
      "eval_loss": 0.09204225242137909,
      "eval_runtime": 672.3262,
      "eval_samples_per_second": 1.681,
      "eval_steps_per_second": 0.561,
      "step": 1280
    },
    {
      "epoch": 1.705179282868526,
      "grad_norm": 0.19780515134334564,
      "learning_rate": 0.0002,
      "loss": 0.0833,
      "step": 1284
    },
    {
      "epoch": 1.7104913678618858,
      "grad_norm": 0.16642864048480988,
      "learning_rate": 0.0002,
      "loss": 0.0788,
      "step": 1288
    },
    {
      "epoch": 1.7158034528552457,
      "grad_norm": 0.18923357129096985,
      "learning_rate": 0.0002,
      "loss": 0.0762,
      "step": 1292
    },
    {
      "epoch": 1.7211155378486056,
      "grad_norm": 0.19858945906162262,
      "learning_rate": 0.0002,
      "loss": 0.083,
      "step": 1296
    },
    {
      "epoch": 1.7264276228419655,
      "grad_norm": 0.20866845548152924,
      "learning_rate": 0.0002,
      "loss": 0.0812,
      "step": 1300
    },
    {
      "epoch": 1.7317397078353254,
      "grad_norm": 0.25259771943092346,
      "learning_rate": 0.0002,
      "loss": 0.102,
      "step": 1304
    },
    {
      "epoch": 1.7370517928286853,
      "grad_norm": 0.15862686932086945,
      "learning_rate": 0.0002,
      "loss": 0.0766,
      "step": 1308
    },
    {
      "epoch": 1.7423638778220452,
      "grad_norm": 0.21982423961162567,
      "learning_rate": 0.0002,
      "loss": 0.0905,
      "step": 1312
    },
    {
      "epoch": 1.747675962815405,
      "grad_norm": 0.2130889743566513,
      "learning_rate": 0.0002,
      "loss": 0.0841,
      "step": 1316
    },
    {
      "epoch": 1.752988047808765,
      "grad_norm": 0.21084699034690857,
      "learning_rate": 0.0002,
      "loss": 0.0886,
      "step": 1320
    },
    {
      "epoch": 1.7583001328021248,
      "grad_norm": 0.17266468703746796,
      "learning_rate": 0.0002,
      "loss": 0.0913,
      "step": 1324
    },
    {
      "epoch": 1.7636122177954847,
      "grad_norm": 0.1931689828634262,
      "learning_rate": 0.0002,
      "loss": 0.0732,
      "step": 1328
    },
    {
      "epoch": 1.7689243027888446,
      "grad_norm": 0.20612108707427979,
      "learning_rate": 0.0002,
      "loss": 0.0846,
      "step": 1332
    },
    {
      "epoch": 1.7742363877822045,
      "grad_norm": 0.19061186909675598,
      "learning_rate": 0.0002,
      "loss": 0.0749,
      "step": 1336
    },
    {
      "epoch": 1.7795484727755644,
      "grad_norm": 0.2851199209690094,
      "learning_rate": 0.0002,
      "loss": 0.0872,
      "step": 1340
    },
    {
      "epoch": 1.7848605577689243,
      "grad_norm": 0.23711121082305908,
      "learning_rate": 0.0002,
      "loss": 0.0913,
      "step": 1344
    },
    {
      "epoch": 1.7901726427622842,
      "grad_norm": 0.22591067850589752,
      "learning_rate": 0.0002,
      "loss": 0.1095,
      "step": 1348
    },
    {
      "epoch": 1.795484727755644,
      "grad_norm": 0.25371497869491577,
      "learning_rate": 0.0002,
      "loss": 0.0947,
      "step": 1352
    },
    {
      "epoch": 1.800796812749004,
      "grad_norm": 0.19923409819602966,
      "learning_rate": 0.0002,
      "loss": 0.0802,
      "step": 1356
    },
    {
      "epoch": 1.8061088977423638,
      "grad_norm": 0.18003644049167633,
      "learning_rate": 0.0002,
      "loss": 0.0788,
      "step": 1360
    },
    {
      "epoch": 1.8114209827357237,
      "grad_norm": 0.1874413788318634,
      "learning_rate": 0.0002,
      "loss": 0.0845,
      "step": 1364
    },
    {
      "epoch": 1.8167330677290838,
      "grad_norm": 0.2261747568845749,
      "learning_rate": 0.0002,
      "loss": 0.0857,
      "step": 1368
    },
    {
      "epoch": 1.8220451527224437,
      "grad_norm": 0.2567504942417145,
      "learning_rate": 0.0002,
      "loss": 0.087,
      "step": 1372
    },
    {
      "epoch": 1.8273572377158036,
      "grad_norm": 0.19099506735801697,
      "learning_rate": 0.0002,
      "loss": 0.0831,
      "step": 1376
    },
    {
      "epoch": 1.8326693227091635,
      "grad_norm": 0.22272682189941406,
      "learning_rate": 0.0002,
      "loss": 0.1005,
      "step": 1380
    },
    {
      "epoch": 1.8379814077025234,
      "grad_norm": 0.2014099508523941,
      "learning_rate": 0.0002,
      "loss": 0.0948,
      "step": 1384
    },
    {
      "epoch": 1.8432934926958833,
      "grad_norm": 0.24469660222530365,
      "learning_rate": 0.0002,
      "loss": 0.1002,
      "step": 1388
    },
    {
      "epoch": 1.8486055776892432,
      "grad_norm": 0.19430527091026306,
      "learning_rate": 0.0002,
      "loss": 0.0824,
      "step": 1392
    },
    {
      "epoch": 1.853917662682603,
      "grad_norm": 0.255005419254303,
      "learning_rate": 0.0002,
      "loss": 0.0846,
      "step": 1396
    },
    {
      "epoch": 1.859229747675963,
      "grad_norm": 0.17546357214450836,
      "learning_rate": 0.0002,
      "loss": 0.0863,
      "step": 1400
    },
    {
      "epoch": 1.8645418326693228,
      "grad_norm": 0.24910494685173035,
      "learning_rate": 0.0002,
      "loss": 0.0999,
      "step": 1404
    },
    {
      "epoch": 1.8698539176626827,
      "grad_norm": 0.22148345410823822,
      "learning_rate": 0.0002,
      "loss": 0.0826,
      "step": 1408
    },
    {
      "epoch": 1.8698539176626827,
      "eval_loss": 0.09065347909927368,
      "eval_runtime": 822.8289,
      "eval_samples_per_second": 1.373,
      "eval_steps_per_second": 0.458,
      "step": 1408
    },
    {
      "epoch": 1.8751660026560426,
      "grad_norm": 0.2651419937610626,
      "learning_rate": 0.0002,
      "loss": 0.0761,
      "step": 1412
    },
    {
      "epoch": 1.8804780876494025,
      "grad_norm": 0.21444730460643768,
      "learning_rate": 0.0002,
      "loss": 0.0849,
      "step": 1416
    },
    {
      "epoch": 1.8857901726427624,
      "grad_norm": 0.1867867112159729,
      "learning_rate": 0.0002,
      "loss": 0.068,
      "step": 1420
    },
    {
      "epoch": 1.8911022576361223,
      "grad_norm": 0.2351546585559845,
      "learning_rate": 0.0002,
      "loss": 0.0907,
      "step": 1424
    },
    {
      "epoch": 1.8964143426294822,
      "grad_norm": 0.26589059829711914,
      "learning_rate": 0.0002,
      "loss": 0.075,
      "step": 1428
    },
    {
      "epoch": 1.901726427622842,
      "grad_norm": 0.20934125781059265,
      "learning_rate": 0.0002,
      "loss": 0.0918,
      "step": 1432
    },
    {
      "epoch": 1.907038512616202,
      "grad_norm": 0.33428141474723816,
      "learning_rate": 0.0002,
      "loss": 0.0974,
      "step": 1436
    },
    {
      "epoch": 1.9123505976095618,
      "grad_norm": 0.25184348225593567,
      "learning_rate": 0.0002,
      "loss": 0.0809,
      "step": 1440
    },
    {
      "epoch": 1.9176626826029217,
      "grad_norm": 0.25616997480392456,
      "learning_rate": 0.0002,
      "loss": 0.0967,
      "step": 1444
    },
    {
      "epoch": 1.9229747675962816,
      "grad_norm": 0.18237841129302979,
      "learning_rate": 0.0002,
      "loss": 0.081,
      "step": 1448
    },
    {
      "epoch": 1.9282868525896415,
      "grad_norm": 0.19491373002529144,
      "learning_rate": 0.0002,
      "loss": 0.0939,
      "step": 1452
    },
    {
      "epoch": 1.9335989375830014,
      "grad_norm": 0.25738468766212463,
      "learning_rate": 0.0002,
      "loss": 0.0745,
      "step": 1456
    },
    {
      "epoch": 1.9389110225763613,
      "grad_norm": 0.24758599698543549,
      "learning_rate": 0.0002,
      "loss": 0.0987,
      "step": 1460
    },
    {
      "epoch": 1.9442231075697212,
      "grad_norm": 0.2540081739425659,
      "learning_rate": 0.0002,
      "loss": 0.093,
      "step": 1464
    },
    {
      "epoch": 1.949535192563081,
      "grad_norm": 0.21376396715641022,
      "learning_rate": 0.0002,
      "loss": 0.0797,
      "step": 1468
    },
    {
      "epoch": 1.954847277556441,
      "grad_norm": 0.24467168748378754,
      "learning_rate": 0.0002,
      "loss": 0.1038,
      "step": 1472
    },
    {
      "epoch": 1.9601593625498008,
      "grad_norm": 0.1739387959241867,
      "learning_rate": 0.0002,
      "loss": 0.064,
      "step": 1476
    },
    {
      "epoch": 1.9654714475431607,
      "grad_norm": 0.23852472007274628,
      "learning_rate": 0.0002,
      "loss": 0.0836,
      "step": 1480
    },
    {
      "epoch": 1.9707835325365206,
      "grad_norm": 0.21905753016471863,
      "learning_rate": 0.0002,
      "loss": 0.0873,
      "step": 1484
    },
    {
      "epoch": 1.9760956175298805,
      "grad_norm": 0.3328015208244324,
      "learning_rate": 0.0002,
      "loss": 0.0826,
      "step": 1488
    },
    {
      "epoch": 1.9814077025232404,
      "grad_norm": 0.2214728593826294,
      "learning_rate": 0.0002,
      "loss": 0.0926,
      "step": 1492
    },
    {
      "epoch": 1.9867197875166003,
      "grad_norm": 0.26229503750801086,
      "learning_rate": 0.0002,
      "loss": 0.0845,
      "step": 1496
    },
    {
      "epoch": 1.9920318725099602,
      "grad_norm": 0.29770365357398987,
      "learning_rate": 0.0002,
      "loss": 0.1108,
      "step": 1500
    },
    {
      "epoch": 1.99734395750332,
      "grad_norm": 0.1678500920534134,
      "learning_rate": 0.0002,
      "loss": 0.0811,
      "step": 1504
    },
    {
      "epoch": 2.00265604249668,
      "grad_norm": 0.17847248911857605,
      "learning_rate": 0.0002,
      "loss": 0.0904,
      "step": 1508
    },
    {
      "epoch": 2.00796812749004,
      "grad_norm": 0.3317367434501648,
      "learning_rate": 0.0002,
      "loss": 0.0821,
      "step": 1512
    },
    {
      "epoch": 2.0132802124833997,
      "grad_norm": 0.214708611369133,
      "learning_rate": 0.0002,
      "loss": 0.0943,
      "step": 1516
    },
    {
      "epoch": 2.0185922974767596,
      "grad_norm": 0.2715078890323639,
      "learning_rate": 0.0002,
      "loss": 0.0866,
      "step": 1520
    },
    {
      "epoch": 2.0239043824701195,
      "grad_norm": 0.23435331881046295,
      "learning_rate": 0.0002,
      "loss": 0.0883,
      "step": 1524
    },
    {
      "epoch": 2.0292164674634794,
      "grad_norm": 0.23222310841083527,
      "learning_rate": 0.0002,
      "loss": 0.0909,
      "step": 1528
    },
    {
      "epoch": 2.0345285524568393,
      "grad_norm": 0.22051915526390076,
      "learning_rate": 0.0002,
      "loss": 0.0929,
      "step": 1532
    },
    {
      "epoch": 2.039840637450199,
      "grad_norm": 0.2643168866634369,
      "learning_rate": 0.0002,
      "loss": 0.0792,
      "step": 1536
    },
    {
      "epoch": 2.039840637450199,
      "eval_loss": 0.09144840389490128,
      "eval_runtime": 804.3027,
      "eval_samples_per_second": 1.405,
      "eval_steps_per_second": 0.469,
      "step": 1536
    },
    {
      "epoch": 2.045152722443559,
      "grad_norm": 0.24077735841274261,
      "learning_rate": 0.0002,
      "loss": 0.0818,
      "step": 1540
    },
    {
      "epoch": 2.050464807436919,
      "grad_norm": 0.2563033699989319,
      "learning_rate": 0.0002,
      "loss": 0.0977,
      "step": 1544
    },
    {
      "epoch": 2.055776892430279,
      "grad_norm": 0.2824521064758301,
      "learning_rate": 0.0002,
      "loss": 0.0736,
      "step": 1548
    },
    {
      "epoch": 2.0610889774236387,
      "grad_norm": 0.24014653265476227,
      "learning_rate": 0.0002,
      "loss": 0.0772,
      "step": 1552
    },
    {
      "epoch": 2.0664010624169986,
      "grad_norm": 0.30390751361846924,
      "learning_rate": 0.0002,
      "loss": 0.0818,
      "step": 1556
    },
    {
      "epoch": 2.0717131474103585,
      "grad_norm": 0.2767259180545807,
      "learning_rate": 0.0002,
      "loss": 0.0666,
      "step": 1560
    },
    {
      "epoch": 2.0770252324037184,
      "grad_norm": 0.21701262891292572,
      "learning_rate": 0.0002,
      "loss": 0.0694,
      "step": 1564
    },
    {
      "epoch": 2.0823373173970783,
      "grad_norm": 0.23670533299446106,
      "learning_rate": 0.0002,
      "loss": 0.0741,
      "step": 1568
    },
    {
      "epoch": 2.087649402390438,
      "grad_norm": 0.22039034962654114,
      "learning_rate": 0.0002,
      "loss": 0.0763,
      "step": 1572
    },
    {
      "epoch": 2.092961487383798,
      "grad_norm": 0.26349514722824097,
      "learning_rate": 0.0002,
      "loss": 0.0794,
      "step": 1576
    },
    {
      "epoch": 2.098273572377158,
      "grad_norm": 0.22578926384449005,
      "learning_rate": 0.0002,
      "loss": 0.0804,
      "step": 1580
    },
    {
      "epoch": 2.103585657370518,
      "grad_norm": 0.19564269483089447,
      "learning_rate": 0.0002,
      "loss": 0.0797,
      "step": 1584
    },
    {
      "epoch": 2.1088977423638777,
      "grad_norm": 0.25183534622192383,
      "learning_rate": 0.0002,
      "loss": 0.0888,
      "step": 1588
    },
    {
      "epoch": 2.1142098273572376,
      "grad_norm": 0.32709088921546936,
      "learning_rate": 0.0002,
      "loss": 0.089,
      "step": 1592
    },
    {
      "epoch": 2.1195219123505975,
      "grad_norm": 0.2655184864997864,
      "learning_rate": 0.0002,
      "loss": 0.0907,
      "step": 1596
    },
    {
      "epoch": 2.1248339973439574,
      "grad_norm": 0.41722509264945984,
      "learning_rate": 0.0002,
      "loss": 0.0792,
      "step": 1600
    },
    {
      "epoch": 2.1301460823373173,
      "grad_norm": 0.24440313875675201,
      "learning_rate": 0.0002,
      "loss": 0.0655,
      "step": 1604
    },
    {
      "epoch": 2.135458167330677,
      "grad_norm": 0.3162206709384918,
      "learning_rate": 0.0002,
      "loss": 0.0821,
      "step": 1608
    },
    {
      "epoch": 2.140770252324037,
      "grad_norm": 0.2740931510925293,
      "learning_rate": 0.0002,
      "loss": 0.0727,
      "step": 1612
    },
    {
      "epoch": 2.146082337317397,
      "grad_norm": 0.2659883201122284,
      "learning_rate": 0.0002,
      "loss": 0.0847,
      "step": 1616
    },
    {
      "epoch": 2.151394422310757,
      "grad_norm": 0.27600815892219543,
      "learning_rate": 0.0002,
      "loss": 0.0703,
      "step": 1620
    },
    {
      "epoch": 2.1567065073041167,
      "grad_norm": 0.21073979139328003,
      "learning_rate": 0.0002,
      "loss": 0.0722,
      "step": 1624
    },
    {
      "epoch": 2.1620185922974766,
      "grad_norm": 0.23214103281497955,
      "learning_rate": 0.0002,
      "loss": 0.0741,
      "step": 1628
    },
    {
      "epoch": 2.1673306772908365,
      "grad_norm": 0.2593928277492523,
      "learning_rate": 0.0002,
      "loss": 0.0784,
      "step": 1632
    },
    {
      "epoch": 2.1726427622841964,
      "grad_norm": 0.27640095353126526,
      "learning_rate": 0.0002,
      "loss": 0.0925,
      "step": 1636
    },
    {
      "epoch": 2.1779548472775563,
      "grad_norm": 0.30572620034217834,
      "learning_rate": 0.0002,
      "loss": 0.0959,
      "step": 1640
    },
    {
      "epoch": 2.183266932270916,
      "grad_norm": 0.9168195724487305,
      "learning_rate": 0.0002,
      "loss": 0.0874,
      "step": 1644
    },
    {
      "epoch": 2.188579017264276,
      "grad_norm": 0.5934210419654846,
      "learning_rate": 0.0002,
      "loss": 0.0782,
      "step": 1648
    },
    {
      "epoch": 2.193891102257636,
      "grad_norm": 0.2832311987876892,
      "learning_rate": 0.0002,
      "loss": 0.0739,
      "step": 1652
    },
    {
      "epoch": 2.199203187250996,
      "grad_norm": 0.2446870356798172,
      "learning_rate": 0.0002,
      "loss": 0.0769,
      "step": 1656
    },
    {
      "epoch": 2.2045152722443557,
      "grad_norm": 0.2518500089645386,
      "learning_rate": 0.0002,
      "loss": 0.0843,
      "step": 1660
    },
    {
      "epoch": 2.2098273572377156,
      "grad_norm": 0.2653398811817169,
      "learning_rate": 0.0002,
      "loss": 0.0767,
      "step": 1664
    },
    {
      "epoch": 2.2098273572377156,
      "eval_loss": 0.09156953543424606,
      "eval_runtime": 683.4819,
      "eval_samples_per_second": 1.653,
      "eval_steps_per_second": 0.552,
      "step": 1664
    }
  ],
  "logging_steps": 4,
  "max_steps": 7530,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 128,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6032433607941178e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
